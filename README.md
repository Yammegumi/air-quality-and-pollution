# ğŸŒ Air Quality and Pollution Assessment

**Author:** Mateusz Åaski  
**Student ID:** s26102
**Subject:** ASI (Architecture of Solutions and Methodology of AI Implementation)

---

## ğŸ§  Project Overview

### ğŸ” Topic
Assessment of air quality based on selected environmental and demographic factors.

### â— Problem
The project aims to develop a machine learning model that can predict air quality levels across various regions using publicly available data. The goal is to identify high-risk pollution areas and support decision-making for environmental improvement.

---

## ğŸ“Š Dataset

- **Source:** Public dataset from Kaggle: *Air Quality and Pollution Assessment*  
- **Size:** 5000 records  
- **Features:** 9 numerical attributes + 1 target variable (air quality level)

### ğŸ“ˆ Attributes

- **Temperature (Â°C):** Average regional temperature
- **Humidity (%):** Relative humidity
- **PM2.5 Concentration (Âµg/mÂ³):** Fine particulate matter
- **PM10 Concentration (Âµg/mÂ³):** Coarser particulate matter
- **NO2 Concentration (ppb):** Nitrogen dioxide level
- **SO2 Concentration (ppb):** Sulfur dioxide level
- **CO Concentration (ppm):** Carbon monoxide level
- **Proximity to Industrial Areas (km):** Distance to the nearest industrial zone
- **Population Density (people/kmÂ²):** People per square kilometer

### ğŸ¯ Target Variable â€“ Air Quality Levels:
- **Good:** Low pollution
- **Moderate:** Acceptable pollution
- **Poor:** Noticeable pollution, risky for sensitive groups
- **Hazardous:** Very high pollution, a serious health risk

---

## ğŸ¯ Project Goals

1. **Build a predictive model:**
   - Classify air quality levels as: Good, Moderate, Poor, Hazardous

2. **Analyze feature influence:**
   - Identify key attributes impacting air quality

3. **Develop actionable insights:**
   - Recommend environmental improvement strategies for specific regions

---

## ğŸ“† Timeline & Workflow

- Short iterations (1â€“2 days per goal)
- Workflow:
  1. Data acquisition
  2. Preprocessing
  3. Exploratory Data Analysis (EDA)
  4. Model training
  5. Evaluation & optimization
  6. Results & recommendations

---

## ğŸ—‚ï¸ Repository Structure

- `README.md` â€“ Project documentation  
- `data/` â€“ Raw dataset files  
- `notebooks/` â€“ Jupyter Notebooks  
- `models/` â€“ Trained ML models  
- `results/` â€“ Analysis outputs and visualizations  
- `.idea/` â€“ IDE config files (e.g. PyCharm)  
- `dags/` â€“ Apache Airflow DAG definitions  
- `raports/` â€“ Project reports and findings  
- `screenshots/` â€“ Screenshots showing DAG functionality (as required by PRO4)  
- `scripts/` â€“ Helper/automation scripts  
- `.gitignore` â€“ Git ignore rules  
- `LICENSE` â€“ License info  
- `docker-compose.yaml` â€“ Docker Compose config for Airflow  
- `requirements.txt` â€“ Python dependencies

---

## ğŸ§ª Project Backlog

- Acquire data and set up the environment
- Data preprocessing and EDA
- Build and train the prediction model
- Test and tune the model
- Present the results

---

## ğŸ³ How to Run Apache Airflow with Docker

**Make sure Docker and Docker Compose are installed.**

### 1. Clone the repository

```bash
git clone https://github.com/YourUsername/s26102-Air-Quality-And-Pollution.git
cd s26102-Air-Quality-And-Pollution
```

### 2. Install Docker & Docker Compose

If not installed, download them from the official [Docker](https://www.docker.com) site.

### 3. Start Airflow

In the root project directory, run:

```bash
docker-compose up -d
```

This will pull the images, create containers, and launch Airflow in the background.

### 4. Check container status

```bash
docker-compose ps
```

### 5. Open Airflow web interface

Visit: [http://localhost:8080](http://localhost:8080)

---

